{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdeutchman/watson/blob/Akira/Watson_Elementary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import library "
      ],
      "metadata": {
        "id": "rtQQhNKtRbc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "mCsAGAegRlrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ccVJEloURssN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download data"
      ],
      "metadata": {
        "id": "5UbLzfnpRt0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/train.csv')"
      ],
      "metadata": {
        "id": "po7ajeSrRwRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory data analysis"
      ],
      "metadata": {
        "id": "yJYn2oS-R7_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "id": "Y2caticZSp9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing data for input"
      ],
      "metadata": {
        "id": "9Epj0s6wTT5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#strip\n",
        "#removes all the whitespaces at the beginning and the end of a string\n",
        "texts = [\n",
        "    '   Bonjour, comment ca va ?     ',\n",
        "    '    Heyyyyy, how are you doing ?   ',\n",
        "    '        Hallo, wie gehts ?     '\n",
        "]\n",
        "[text.strip() for text in texts]"
      ],
      "metadata": {
        "id": "5nHmrMvbT_8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replace\n",
        "text = \"I love koalas, koalas are the cutest animals on Earth.\"\n",
        "text.replace(\"koala\", \"panda\")"
      ],
      "metadata": {
        "id": "CPR4GulpUBWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting\n",
        "text = \"linkin park / metallica /red hot chili peppers\"\n",
        "text.split(\"/\")"
      ],
      "metadata": {
        "id": "OKxcrVsZVVLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lowercase\n",
        "text = \"i LOVE football sO mUch. FOOTBALL is my passion. Who else loves fOOtBaLL ?\"\n",
        "text.lower() "
      ],
      "metadata": {
        "id": "8_t-cN7NVW-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dealing with numbers, punctuation, and symbols\n",
        "\n",
        "#numbers\n",
        "text = \"i do not recommend this restaurant, we waited for so long, like 30 minutes, this is ridiculous\"\n",
        "cleaned_text = ''.join(char for char in text if not char.isdigit())\n",
        "\n",
        "#punctuation and symbols\n",
        "import string # \"string\" module is already installed with Python\n",
        "string.punctuation\n",
        "for punctuation in string.punctuation:\n",
        "    text = text.replace(punctuation, '') \n",
        "\n"
      ],
      "metadata": {
        "id": "G-XztAypVZJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokeninzing\n",
        "text = 'It is during our darkest moments that we must focus to see the light'\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokens = word_tokenize(text)"
      ],
      "metadata": {
        "id": "fZlEAwo1VeSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing stopwords\n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "tokens = [\"i\", \"am\", \"going\", \"to\", \"go\", \"to\", \"the\", \n",
        "        \"club\", \"and\", \"party\", \"all\", \"night\", \"long\"]\n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "tokens_cleaned = [w for w in tokens if not w in stop_words] "
      ],
      "metadata": {
        "id": "Er23yMv6VjHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmatizing\n",
        "#Lemmatizing is a technique used to find the root of words, in order to group them by their meaning rather than by their exact form\n",
        "\n",
        "# Lemmatizing the verbs\n",
        "verb_lemmatized = [                  \n",
        "    WordNetLemmatizer().lemmatize(word, pos = \"v\") # v --> verbs\n",
        "    for word in tokenized_sentence_no_stopwords\n",
        "]\n",
        "\n",
        "# 2 - Lemmatizing the nouns\n",
        "noun_lemmatized = [                 \n",
        "    WordNetLemmatizer().lemmatize(word, pos = \"n\") # n --> nouns\n",
        "    for word in verb_lemmatized\n",
        "]"
      ],
      "metadata": {
        "id": "9uzSLZWwWzkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# High dimensional Embedding"
      ],
      "metadata": {
        "id": "BUSynbhMUCdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Each word is represented by a vector of chosen length"
      ],
      "metadata": {
        "id": "nuYs1qK7YWa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1_bbPJPTZD1z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}